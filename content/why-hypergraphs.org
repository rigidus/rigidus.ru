http://blog.opencog.org/2013/03/24/why-hypergraphs/


* Почему гиперграфы

  OpenCog использует =гиперграфы= для представления
  информации. Почему?  Я не думаю что кто-то ясно и лаконично объяснил
  это где-то в другом месте, так что я попытаюсь сделать это здесь.

  Это очень важный момент: я не могу сказать вам как много раз я
  отправлялся на поиски какой-нибудь крутой системы логического
  программирования или логического вывода или автоматического
  доказательства теорем или =graph-rewritin-engine= или =системы
  вероятносного программирования= и потом опускал руки и понимал, что
  после множества потерянных часов ничего из этого не делает то, что я
  хочу. Если вы заинтересованы в AGI позвольте мне заверить вас: это
  не делает то что вы хотите, или погодите-ка... Что я, собственно,
  хочу чтобы они делали и почему?

  Итак, давайте начнем с простого: с системы, переписывающей
  граф. Сегодня почти каждый согласится с тем, что лучший путь
  представления знаний – это граф. Структура IsA(Cat, Animal) выглядит
  как граф с двумя вершинами: Саt и Animal, и помеченным ребром IsA,
  между ними. Если я также знаю, что IsA(Binky, Cat), то, в принципе,
  я могу быть в состоянии вывести, что IsA(Binky, Animal). Это простые
  транзитивные отношения, и действие логической дедукции, в данном
  примере, представляет собой простой правило переписывания графа:
  если вы видите два IsA-ребра в строке, вы должны нарисовать третью
  IsA-ребро между первой и последней вершинами. Легко, верно?

  Поэтому, возможно, вы подумаете, что все логические индукции и
  системы вывода имеют систему переписывания графов в основе, так? На
  самом деле, почти никто из них так не делает. А те, что делают,
  делают этокаким-то внутренним, специальным, непубличным,
  недокументированным способом: нет там никакого API, это не
  показывается; это в не "официальной" части системы, пока вы ее
  используете или переделываете.

  Окей, так зачем мне нужны графы? Ну, я работаю над синтактическим
  парсингом естествнного языка, так называемого Viterbi decoder for
  Link Grammar. Мой первоначальный граф – это строка слов:
  предложение. Вершинами являются слова, а ребрами - стрелки,
  называемые "следующее слово". Очень просто. Чтобы проанализировать
  это предложение, я хочу применить определенный набор простых правил,
  переписывающих граф: например, если слово =x= - существительное, то
  надо создать стрелку, называемую "части речи" (part-of-speech, POS),
  от слова =X= к специальной вершине "имя существительное". Если
  слово, стоящее перед словом =X= - это прилагательное (т. е. если оно
  имеет POS-стрелку "прилагательное"), тогда создать новую стрелку
  "модификатор существительного", направленной от =X= к этому слову,
  которое стоит до него. Этот вид графа называется "dependency
  parsing", и очень популярен, чтоб делать анализ естественного
  обычного языка. Итак, вы думаете, что все dependency parsers
  используют системы переписывающие графы в своем ядре? Вряд ли. Если
  они это делают, то являются незадокументированными, сломанными и
  т.д... Идея понятна.

  Единственный dependency parser, который я знаю, явно использующий в
  себе явно систему, переписывающую граф, и открытую для модификации,
  и даже документированную (!) - это RelEx. И это прекрасно! Хотя
  RelEx использует свою самоизобретенную кастомную систему
  переписывания графов, я думаю, он мог бы использовать некоторые
  другие, уже существующие систему чтобы сделать это. (На самом деле
  нет, потому что в 2005-ом не было систем переписывания графов с
  открытым исходным кодом. Неважно).

  Что еще я хочу? Ну, я мечтаю о том, чтобы с помощью машинного
  обучения обучать систуму новым правилам! Я имею в виду, это и есть
  цель AGI да?  Иметь машину, которая может учиться новым вещам? Окей,
  для изучения новых вещей, как мы видим, я должен иметь какой-то
  простой синтаксис для представления правил. Базирующийся на простом
  языке графов. Вы думаели, что все системы переписывающие графы имеют
  какой-то простой в использовании язык, правильно? Нет. Решительно,
  черт возьми, нет. С одним исключением, может быть, вам придется
  программировать на Java или C++ или C#.net. К сожалению, моя система
  машинного обучения еще не знает, как программировать на этих языках.

  Здесь я прихожу к озарению: Было бы удобно, если бы я мог выразить
  правила переписывающие графы - как сами графы. Было бы удобно, если
  бы я мог выразить логические импликации, как сами графы. Было бы
  удобно если мой язык программирования графов, мог быть сам записан в
  виде графа. Да, это возможно. Пока что самый простой способ сделать
  это, если граф на самом деле - гиперграф. Я объясню почему в в
  абзаце ниже.

  Если я имею систему, переписывающую гиперграф, тогда я могу иметь
  место, где я могу объединить обрабоку естественного языка,
  логический вывод и машинное обучение в одном месте. Итак я думаю что
  любой, кто пробовал построить AGI систему основывал бы ее на
  гиперграфе, верно?  Нет, вы ошибаетесь. Видимо, OpenCog единственная
  система, которая это делает. Сейчас OpenCog реализация имеет много
  дизайнерских нагромождений и архитектурных недостатков. Его трудно
  понять и трудно использовать. Но теперь, возможно, теперь вы
  понимаете, почему я клялся в верности этой системе, вместо того,
  чтобы сбежать с какой-то другой системе рассуждений или к парсеру
  или Байесовской сети или любой другой.

* Математические основания

  В данном разделе, я постараюсь применить все вышеописанные замечания
  на прочной математической основе, с привлечением теории моделей,
  теории категорий, (и даже N-категорий!), и теории типов.
  Результатом всего этого станет самый простой способ для
  представления структур данных, так что алгоритмы машинного обучения
  могут обучаться им, а затем применить их к парсингу естественного
  языка, логическому выводу представлению структур данных как
  гиперграфов.

  Из model theory и computer science мы знаем понятие цифровой
  подписи: набор функций, который берет некоторое количество
  аргументов и возвращает какое-то значение (как подпись в Java или
  C++). Если на секунду прогнорировать типы (что делает lisp и
  scheme), то, в принципе, можно передать любые значения в любом
  порядке любой функции, и укладывать их как угодно, даже
  рекурсивно. Это называется "алгебра термов" или точнее "алгебра
  свободных термов" или “free theory”. Если функции не имеют имен, они
  анонимны, тогда это лямбда-исчисление.

  Один из способов представить себе элемент алгебры термов - это
  ориентированный древовидный граф. Итак, если мы имеем две функции
  =f(х,у)= и =g(х,y)= и три константы =а=, =b=, =c=, то =f(a,
  g(b,c))= - это двоичное дерево, с =f= в верхнем узле, =g= – в левом
  узле, и =a=, =b= и =c=, в качестве листьев. Термин "алгебра" тогда
  просто совокупность всех таких деревьев. Ни больше, ни меньше.

  Для того чтобы запрограммировать что-то полезное необходимы в
  предикаты или отношения: вещи, которые имеют значения истинности и
  упорядочивают термы. Таким образом, "больше чем" - это отношение и
  "a>b" может быт истинно или ложно. Отношения могут быть также IsA,
  HasA, BelongTo, LivesIn, EmployedAt. Последние два примера долдны
  очистить эти "реляционные алгебры" от от реляционных базы данных,
  таких как SQL или NoSQL. Отношения комбинируются с логическими
  операторами: (employee X LivesIn city Y AND ReportsTo dept Z в
  качестве текстового примера.

  В целом, это сочетает в себе алгебру термов и реляционную алгебру,
  так, что можно записать =3<f(x,y)= где =f(x,y)= это терм, =<= это
  отношение, =3= - это константа. Добавив к этому специальные
  свободные переменные связанные с опреаторами ForAll и ThereExists
  получим логику первого порядка. К примеру: =ForAll x ThereExists y
  such that 3<f(x,y)=.

  Особый случаей отношений - это правило переписывания термов. Это
  отношение берет терм и заменяет его на другой терм, например:
  =ab->c=, говоря "всегда, когда ты видишь строку "ab" замени ее на
  "с". BNF-нотация компьютерных языков - это просто коллекция термов,
  переписывающих отношения. Она использует term rewriting system чтобы
  парсить (формальные) языки. Переписывание графов - это просто
  вариация этого - всегда, когда ты видишь граф =X= замени его на граф
  -Y=.

  До сих пор я избегал вопроса о типах. В программировании типы
  позволяют типобезопасность. Типа делают код более читабельным:
  =f(string, int)= менее мистично, чем =f(x,y)=. Типы решают некоторые
  абстрактные проблемы лямбда-исчисления. Правила переписывания в
  BNF-нотации типизированыые: подстановка =а->bc= имеет место не для
  любого =а=, а только когда =а= - веб-страница или IP-аддрес или
  URL. Правило переписывания графов говорит: "всегда, когда ты видишь
  =x=, замени его на "y" неявно завися от того что =x= типизировано:
  =x= не может быть просто любым, оно имеет специфический вид графа,
  имеет специфическую форму и связь. Правила применяется для всех
  графов, которые имеют эту форму, этот вид или тип. Итак, правило
  переписывания =x->y= на самом деле (type x)->(type y). Графически
  это остается двумя точками, =x= и =y= с направленным ребром между
  ними, Ой, подождите, =x= и =y= не точки, =x= и =y= - графы. Какой
  граф имеет графы в качестве точек? Какой вид графа имеет ребра между
  графами? А-аа, гиперграф!

  И это главный "Aга!"-момент. Однажды увидев это вы начинаете видеть
  гиперграфы. Разумеется, вы можете визуализировать =Set(a,b,c)= в
  виде дерева, c =Set= в качестве родительского узла, и трех детей:
  =a=, =b=, =c=. Или вы можете визуализировать это как гиперграф:
  =Set= как "ссылку" (с тремя узлами, а не двумя) и точками =a=, =b=,
  =c=, содержащимися в ссылке. По факту, все гиперграфы эквивалентны
  этим ориентированным деревьям; если у вас есть один, вы можете иметь
  и другой. Гиперграфы лишь удобное обозначение.

  Давайте воспользуемся моментом, чтоб посмотреть, что только что
  случилось: функция =f(x,y,z)= – это просто гипер-ребро =f=,
  соединяющая три узла =x=, =y=, =z=. Логическое выражение =a AND b
  AND c= может быть написано как =AND(a,b,c)=, которое показывает
  специфический пример эквивалентности гиперграфа. Это может быть
  записано как правило редукции: =(a AND b AND c) -> AND(a,b,c)=,
  которое само просто гиперграф формы =x->y=, с =x= и =y=
  гиперграфами. Первоочередные логические конструкты "for-all" и
  "thеre-exists" - просто спецальные случаи связывания в
  лямбда-исчислении, связывающие операцию лямбда, которая связывает
  свободные переменные в выражение. Снова, гиперграфы: лямбда – это
  просто гиперссылка, котороя свяывает пеерменную =x= в выражении =y=,
  и =y=, это просто терм, кхм, гиперграф!

  Я упоминал о категориях и n-категориях (categories и n-categories),
  и я предполагаю, должен оправдать это упоминание. Поскольку теория
  категорий является теорией точек и стрелок, тогда переписывающее
  правило между графами -это морфизм в категории маленьких
  диаграмм. Тонкий, но важный момент о теории категорий, которая почти
  никогда не обсуждался в intro-to-cat-theory текстах, заключается в
  том, что все объекты неявно типизированные. В категории множеств
  объекты одного и того де типа: они множества. Это не упоминается,
  так как в данной категории, все объекты одного типа; типы меняются
  только когда функтор мапит одно множество к другому. Так, чтобы
  понять категорико-теоритический эквивалент типов в computer science,
  мы должны думать о функторах. Но как мы только что видели,
  графо-переписывающее правило – это морфизм между функторами. Так что
  мы могли бы сказать, что переписывание графа – это категория Cat
  маленьких категорий. Или вы могли бы скользить по другому
  направлению и начать называть это 2-категорией. Как
  угодно. Возможно, полезно было бы отметить, что алгоритмы
  переписывающие графы иногда выражены как one-pushouts или
  2-pushouts, где pushout – определенная категорико-теоритическая
  концепция. Примечательно для переписывания графов, что любые
  категории с pushouts и equalizers имеют (co-)limits. Кроме того, как
  мы только что видели, мы хотим систему, перепимывающую гиперграфы
  системы, а не графы Вот так.

* Для чего еще они хороши?

  В OpenCog, типы Link и Node наследуются от типа Atom. Эта концепция
  именования намеренно внушает: "Атом" мыслится как понятие "атомной
  формулы" от теории моделей или логики первого порядка: так, эта
  формала не имеет переменных (полностью grounded определена?) и это
  делает ее истинным значением (не составным логическим соединением и
  не имеющим квантификторов в себе). Это внушение именует помощь
  помогает установить интендет использование гипергарофов с уважением
  к логике первого порядка

  Истинное значение отличается важностью. По умолчанию (в простейшем
  случае) OpenCog истинное значение - это пара чисел с плавающей
  точкой: a probability and a confidence. Эти числа разрешают several
  другие AI-концепции to be mapped into hypegraphs: Байесовские сети,
  Марковские сети и искуственные нейронные сети. Все они - графы:
  направленные графы, at that. Они отличаются в тома как они связывают
  и распространяют probabilitues с плавающей точкой, энтропии и
  активации. Идеи, sush as Марковские логические сети, которое
  имплементируют принципы максимальной энтропии (aka Boltzmann
  parition function) на сети выражений логики первого порядка, могут
  представлены с OpenCog гиперграфами. Ох, я должен упомиянуть PLN
  (Probabilistic Logic Networks), which is what the atomspace was
  originally designed for. Что мне нравится в OpenCog hypergraph
  atomspace: он имеет  a tremendously powerful ability to succinctly
  and easily represent complex modern AI concepts.

* Хороший, плохой и ужасный

  Вы слышали о хорошем. Сейчас про плохое и ужасное. Для начала
  реализация OpenCog atomspace является медленной и неэффективной,
  излишне сложной, плохо спроектированной, слабо-распределенной,
  немасштабируемой, однопоточная. Но давайте не будем останавливаться
  на этом. Все это может быть поправимо после приложения
  программистких усилий (и глубокого архитектурного мышления). Это все
  горячо обсуждалось в прошлом. Когда-нибудь, может быть все это будет
  исправлено.

  Плохой вещью о OpenCog atomspace также является то, что почти никто
  не понимает, что, хм, это - язык программирования. Позвольте мне
  быть предельно ясным в этом вопросе: OpenCog реализует правила
  переписывания графов с [ImplicationLink]. Последовательность
  ImplicationLink может быть использована для вычисления вещей. В этом
  смысле это что-то похожее на язык [Graph Programs], за исключением
  того, что OpenCog разрешает дробные значения истинности, логическое
  программирование и другие хорошие вещи. Если мы будем придерживаться
  использования ImplicationLink с четкими значениями истинности (T/F),
  то полученная система будет по существу Прологом. Разумеется вы
  знаете, что Пролог является популярным для программирования
  искуственного интеллекта, потому что легко писать системы вывода,
  экспертные системы и тому подобное на Прологе. Что вы можете не
  знать, так это то что тесно связано с Прологом - [Answer-Set
  Programming (ASP)]. Фактически ASP использует точно такую же нотацию
  что и Пролог. Отличие только в двух важных вещах: во-первых, когда
  вы запускаете программу на Прологе вы получаете один ответ. С ASP вы
  получаете ответы на все вопросы! Это значительно более мощно и
  причина этого заключается в том, что современные ASP-решатели
  построены на вершине современных [Boolean SAT solvers]. Which means
  that they are stunningly efficient and effective.


So what does this have to do with OpenCog? Well, here we have a system
that, using ImplicationLinks, is essentially Prolog, more or less,
when run in crisp-logic mode. Or, you could say, its like typed Lambda
calculus. But do we have a simple, easy-to-use syntax like Prolog for
it? No we don’t. That’s bad. Can we take an existing Prolog program,
run a tool on it, and convert it to ImplicationLinks? No we don’t.
Would it run fast? No it wouldn’t: it would probably be slower than
the slowest Prolog ever: Borland prolog running on a 5MHz IBM PC AT
in 1986.  And forget an ASP solver for OpenCog.  For the special case
where all OpenCog truth values are crisp T/F values, we do not have a
Boolean SAT solver to find solutions for our graphs of
ImplicationLinks.  This is bad, Really Bad. But I think that this is
because very few people seem to understand that the OpenCog Atomspace
really is a petri dish for programming languages.

Heck, we don’t even have anything equivalent to the RelEx Sentence
Algorithms for OpenCog, even though RelEx is OpenCog-like. This
absence is slowing down my efforts to continue work on the
Link-Grammar parser, and to move natural language processing out of
its stand-alone arena, into a general, flexible framework.

(And we’ve barely scratched the surface. In order to make implication
and pattern mining run quickly in the atomspace, we need to implement
something like the concept of ‘memoization‘ from lisp/scheme. But it
turns out that memoization is really just a relational algebra: it is
a database of short expressions that stand in for long ones. The
OpenCog Atomspace is also, among other things, a relational database
that can store and query not only flat tables or key-value pairs, but
full-blown hypergraphs. And this isn’t a day-dream; its crucial for
performance (and its partially implemented)).

Why don’t we have these things? Well, its hard. Its just not easy. We
don’t have the infrastructure to make it easy, and we don’t have the
users who demand these tools.   I don’t think most users are even
aware of what the atomspace could even do.   Almost no one is thinking
about ‘how to program in the language of OpenCog’ even though it has
the potential of far surpassing any of the existing probabilistic
programming languages out there.  Its time to change all this, but it
will take someone smart and dedicated to do this. Many someones. This
could be you.
